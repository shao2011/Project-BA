{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10286340,"sourceType":"datasetVersion","datasetId":6365616}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U sentence-transformers","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pymongo import MongoClient\nimport pandas as pd\nimport re\nimport emoji\nfrom sentence_transformers import SentenceTransformer\nimport torch\nimport pickle","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Kết nối mongodb\nMONGO_SOURCE_URI = \"mongodb://dsReader:ds_reader_ndFwBkv3LsZYjtUS@178.128.85.210:27017\"\nsource_client = MongoClient(MONGO_SOURCE_URI)\nsource_db = source_client[\"cdp_database\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# lấy các collection cần thiết\nusers_collection = source_db[\"twitter_users\"]\ntweets_collection = source_db[\"tweets\"]\n\n# Đọc file danh sách các KOL\ncsv_file = \"/kaggle/input/danh-sch-kol-twitter/kols_twitter.csv\"\ndf = pd.read_csv(csv_file)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# (optional) Kiểm tra trong số các KOL, có bao nhiêu người có tweets, bao nhiêu người không có tweets","metadata":{}},{"cell_type":"code","source":"def check_KOL_num_tweets(df, tweets_collection):\n    count_tweets = dict()\n    for i in range(len(df)):\n        # lấy id và name của user\n        user_id = df.loc[i, \"_id\"]\n        userName = df.loc[i, \"userName\"]\n\n        # lấy các tweets của user đó\n        tweets = tweets_collection.find({\"author\": str(user_id)}) # x = tweets_collection.find({\"author\": str(1353096979463741440)})        \n        count = 0\n        \n        if tweets == None:\n            count_tweets[user_id] = count\n            print(f\"{user_id} không có tweets trong database\")\n            continue\n            \n        for i in tweets:\n            count += 1\n        count_tweets[user_id] = count\n        print(count)\n\n    # kiểm tra bao nhiêu phần trăm người KHÔNG CÓ tweets trong database\n    count_kol_no_tweets = 0\n    for user_id in count_tweets:\n        if count_tweets[user_id] == 0:\n            count_kol_no_tweets +=1\n    \n    print(\"Số KOL không có tweet nào trong database cả:\", count, \"~\", round(count_kol_no_tweets/len(df)*100))\n    return","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Tiền xử lý các tweets trước khi feed vào model","metadata":{}},{"cell_type":"code","source":"def preprocess_tweet(text):\n    # Replace URLs and mentions\n    text = re.sub(r'http\\S+|www\\S+', '<URL>', text)\n\n    # bỏ tên user đi\n    text = re.sub(r'@\\w+', '@username', text)\n\n    # # Remove hashtags but keep the text\n    text = re.sub(r'#(\\w+)', r'\\1', text)\n\n    # Remove special characters and lowercasing\n    text = re.sub(r'[^\\w\\s]', '', text)\n    text = text.lower()\n\n    # # Normalize emojis\n    text = emoji.demojize(text)\n\n    return text\n\ndef cleaning_tweet(df, tweets_collection):\n    clean_tweets = dict()\n    \n    for i in range(len(df)):\n        user_id = df.loc[i, \"_id\"]\n        userName = df.loc[i, \"userName\"]\n    \n        tweets = tweets_collection.find({\"author\": str(user_id)})\n        if tweets == None:\n            continue\n            \n        tweets_dict = dict()\n        for tweet in tweets:\n            tweet_id = tweet.get(\"_id\")\n            text = tweet.get(\"text\")\n    \n            clean_text =  preprocess_tweet(text)\n            tweets_dict[tweet_id] = clean_text\n        \n        if tweets_dict == {}:\n            continue\n            \n        clean_tweets[user_id] = tweets_dict\n\n    return clean_tweets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Infer embedding cho mỗi user (= avg các embedding của các tweets của user đó)","metadata":{"execution":{"iopub.status.busy":"2024-12-24T10:28:29.919540Z","iopub.execute_input":"2024-12-24T10:28:29.920062Z","iopub.status.idle":"2024-12-24T10:28:36.344271Z","shell.execute_reply.started":"2024-12-24T10:28:29.920027Z","shell.execute_reply":"2024-12-24T10:28:36.342969Z"}}},{"cell_type":"code","source":"def infer_embedding_an_user(tweet_dict, model):\n    sentences = [tweet_dict[tweet_id] for tweet_id in tweet_dict]\n    \n    # Calculate embeddings by calling model.encode()\n    embeddings = model.encode(sentences)\n    print(embeddings.shape)\n\n    user_embedding = torch.mean(torch.Tensor(embeddings), dim=0)\n    return user_embedding\n\ndef infer_embedding_all_users(clean_tweets, model):\n    user_embeddings = dict()\n    for user_id in clean_tweets:\n        if clean_tweets[user_id] == {}:\n            continue\n        user_embeddings[user_id] = infer_embedding_an_user(clean_tweets[user_id], model = model)\n    \n    with open(\"user_embeddings.pkl\", \"wb\") as f:\n        pickle.dump(user_embeddings, f)\n        \n    return user_embeddings\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# RUN","metadata":{"execution":{"iopub.status.busy":"2024-12-24T10:33:56.175463Z","iopub.execute_input":"2024-12-24T10:33:56.175881Z","iopub.status.idle":"2024-12-24T10:33:56.206512Z","shell.execute_reply.started":"2024-12-24T10:33:56.175846Z","shell.execute_reply":"2024-12-24T10:33:56.205280Z"}}},{"cell_type":"code","source":"check_KOL_num_tweets(df, tweets_collection)\n\nclean_tweets = cleaning_tweet(df, tweets_collection)\n\nmodel = SentenceTransformer(\"Twitter/twhin-bert-base\")\n\nuser_embeddings = infer_embedding_all_users(clean_tweets, model)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}